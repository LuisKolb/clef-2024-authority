from typing import List, Tuple, Dict, TypedDict, Union, Optional, NamedTuple
import textwrap
import json 
import os
import re
import numpy as np

class RumorDict(TypedDict):
    id: str
    rumor: str
    label: str
    timeline: List[List[str]]
    evidence: List[List[str]]
    retrieved_evidence: List[List[Union[str, int, float]]]

class RankedDocs(NamedTuple):
    author_account: str
    authority_tweet_id:str
    doc_text: str
    rank: int
    score: float


def load_rumors_from_jsonl(filepath: Union[str, os.PathLike]) -> List[RumorDict]:
    jsons = []
    with open(filepath, encoding='utf8') as file:
        for line in file:
            jsons += [json.loads(line)]
    return jsons


def write_trec_format_output(filename: str, data: List[List[Union[str, int, float]]], tag: str) -> None:
    """
    Writes data to a file in the TREC format.

    Parameters:
    - filename (str): The name of the file to write to.
    - data (List[Tuple[str, int, int, float]]): A list of tuples, where each tuple contains:
        - rumor_id (str): The unique ID for the given rumor.
        - authority_tweet_id (int): The unique ID for the authority tweet.
        - rank (int): The rank of the authority tweet ID for that given rumor_id.
        - score (float): The score given by the model for the authority tweet ID.
    - tag (str): The string identifier of the team/model.
    """
    with open(filename, 'w') as file:
        for rumor_id, authority_tweet_id, rank, score in data:
            line = f"{rumor_id}\tQ0\t{authority_tweet_id}\t{rank}\t{score}\t{tag}\n"
            file.write(line)


def combine_rumors_with_trec_file_judgements(jsons, trec_judgements_path):
    """
    create a list of RankedDocs objects in key retrieved_evidence from TREC-formatted file

    Parameters:
        - jsons: list of json-like rumors from dataset
        - trec_judgements_path: filepath to TREC-formatted file containing rank and score

    Returns:
    list of json-like rumors from dataset, with the key retrieved_evidence populated with a list of RankedDocs-like objects
    """
    trec_by_id = {}

    with open(trec_judgements_path, 'r') as file:
        for line in file:
            rumor_id, _, evidence_id, rank, score, _ = line.split('\t')
            if rumor_id not in trec_by_id:
                trec_by_id[rumor_id] = {}
            trec_by_id[rumor_id][evidence_id] = (rank, score)

    for i, item in enumerate(jsons):
        item['retrieved_evidence'] = []

        doc_ranks = trec_by_id[item['id']]
        for author_account, tweet_id, tweet_text in item['timeline']:
            if tweet_id in doc_ranks:
                rank, score = doc_ranks[tweet_id]
                item['retrieved_evidence'] += [[
                    author_account,
                    tweet_id,
                    tweet_text,
                    int(rank),
                    float(score),
                ]]
        
        jsons[i] = item
    return jsons


def write_jsonlines_from_dicts(filename: Union[str, os.PathLike], dicts: List[Dict]) -> None:
    with open(filename, 'w') as file:
        for item in dicts:
            file.write(f'{json.dumps(item)}\n')


def clean_tweet(text):
    # source: https://github.com/Fatima-Haouari/AuFIN/blob/main/code/utils.py
    if (text is None) or (text is np.nan):
        return ""
    else:
        text = re.sub(r"http\S+", " ", text)  # remove urls
        text = re.sub(r"RT ", " ", text)  # remove rt
        text = re.sub(r"@[\w]*", " ", text)  # remove handles
        text = re.sub(r"[\.\,\#_\|\:\?\?\/\=]", " ", text)  # remove special characters
        text = re.sub(r"\t", " ", text)  # remove tabs
        text = re.sub(r"\n", " ", text)  # remove line jump
        text = re.sub(r"\s+", " ", text)  # remove extra white space
        text = re.sub(r"\u201c", " ", text)  # remove â€œ character
        text = re.sub(r"\u201d", " ", text)  # remove â€œ character
        # accents = re.compile(r'[\u064b-\u0652\u0640]') # harakaat and tatweel (kashida) to remove

        # arabic_punc= re.compile(r'[\u0621-\u063A\u0641-\u064A\d+]+') # Keep only Arabic letters/do not remove numbers
        # text=' '.join(arabic_punc.findall(accents.sub('',text)))
        text = text.strip()
        return text
    
def clean_tweet_aggressive(text):
    # source: https://github.com/Fatima-Haouari/AuFIN/blob/main/code/utils.py
    if (text is None) or (text is np.nan):
        return ""
    else:
        text = re.sub(r"http\S+", " ", text)  # remove urls
        text = re.sub(r"RT ", " ", text)  # remove rt
        text = re.sub(r"@[\w]*", " ", text)  # remove handles
        
        # TODO: does this improve results? hashtags are... whacky; see e.g. rumor AuRED_104
        text = re.sub(r"[\.\,\|\:\?\?\/\=]", " ", text)  # remove special characters

        text = re.sub(r"#[\w]*", " ", text)  # remove handles

        text = re.sub(r"\t", " ", text)  # remove tabs
        text = re.sub(r"\n", " ", text)  # remove line jump
        text = re.sub(r"\s+", " ", text)  # remove extra white space
        text = re.sub(r"\u201c", "", text)  # remove â€œ character
        text = re.sub(r"\u201d", "", text)  # remove â€ character
        text = re.sub(r"\u2018", "", text)  # remove â€˜ character
        text = re.sub(r"\u2019", "", text)  # remove â€™ character
        text = re.sub(r'\"', " ", text)  # remove " character

        # see: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python
        emojis = r"(?:[0-9#*]ï¸âƒ£|[â˜âœŠ-âœğŸ…ğŸ‚ğŸ‡ğŸ‘‚ğŸ‘ƒğŸ‘†-ğŸ‘ğŸ‘¦ğŸ‘§ğŸ‘«-ğŸ‘­ğŸ‘²ğŸ‘´-ğŸ‘¶ğŸ‘¸ğŸ‘¼ğŸ’ƒğŸ’…ğŸ’ğŸ’‘ğŸ’ªğŸ•´ğŸ•ºğŸ–ğŸ–•ğŸ––ğŸ™ŒğŸ™ğŸ›€ğŸ›ŒğŸ¤ŒğŸ¤ğŸ¤˜-ğŸ¤ŸğŸ¤°-ğŸ¤´ğŸ¤¶ğŸ¥·ğŸ¦µğŸ¦¶ğŸ¦»ğŸ§’ğŸ§“ğŸ§•ğŸ«ƒ-ğŸ«…ğŸ«°ğŸ«²-ğŸ«¸][ğŸ»-ğŸ¿]?|â›“(?:ï¸â€ğŸ’¥)?|[â›¹ğŸ‹ğŸŒğŸ•µ](?:ï¸â€[â™€â™‚]ï¸|[ğŸ»-ğŸ¿](?:â€[â™€â™‚]ï¸)?)?|â¤(?:ï¸â€[ğŸ”¥ğŸ©¹])?|ğŸ‡¦[ğŸ‡¨-ğŸ‡¬ğŸ‡®ğŸ‡±ğŸ‡²ğŸ‡´ğŸ‡¶-ğŸ‡ºğŸ‡¼ğŸ‡½ğŸ‡¿]|ğŸ‡§[ğŸ‡¦ğŸ‡§ğŸ‡©-ğŸ‡¯ğŸ‡±-ğŸ‡´ğŸ‡¶-ğŸ‡¹ğŸ‡»ğŸ‡¼ğŸ‡¾ğŸ‡¿]|ğŸ‡¨[ğŸ‡¦ğŸ‡¨ğŸ‡©ğŸ‡«-ğŸ‡®ğŸ‡°-ğŸ‡µğŸ‡·ğŸ‡º-ğŸ‡¿]|ğŸ‡©[ğŸ‡ªğŸ‡¬ğŸ‡¯ğŸ‡°ğŸ‡²ğŸ‡´ğŸ‡¿]|ğŸ‡ª[ğŸ‡¦ğŸ‡¨ğŸ‡ªğŸ‡¬ğŸ‡­ğŸ‡·-ğŸ‡º]|ğŸ‡«[ğŸ‡®-ğŸ‡°ğŸ‡²ğŸ‡´ğŸ‡·]|ğŸ‡¬[ğŸ‡¦ğŸ‡§ğŸ‡©-ğŸ‡®ğŸ‡±-ğŸ‡³ğŸ‡µ-ğŸ‡ºğŸ‡¼ğŸ‡¾]|ğŸ‡­[ğŸ‡°ğŸ‡²ğŸ‡³ğŸ‡·ğŸ‡¹ğŸ‡º]|ğŸ‡®[ğŸ‡¨-ğŸ‡ªğŸ‡±-ğŸ‡´ğŸ‡¶-ğŸ‡¹]|ğŸ‡¯[ğŸ‡ªğŸ‡²ğŸ‡´ğŸ‡µ]|ğŸ‡°[ğŸ‡ªğŸ‡¬-ğŸ‡®ğŸ‡²ğŸ‡³ğŸ‡µğŸ‡·ğŸ‡¼ğŸ‡¾ğŸ‡¿]|ğŸ‡±[ğŸ‡¦-ğŸ‡¨ğŸ‡®ğŸ‡°ğŸ‡·-ğŸ‡»ğŸ‡¾]|ğŸ‡²[ğŸ‡¦ğŸ‡¨-ğŸ‡­ğŸ‡°-ğŸ‡¿]|ğŸ‡³[ğŸ‡¦ğŸ‡¨ğŸ‡ª-ğŸ‡¬ğŸ‡®ğŸ‡±ğŸ‡´ğŸ‡µğŸ‡·ğŸ‡ºğŸ‡¿]|ğŸ‡´ğŸ‡²|ğŸ‡µ[ğŸ‡¦ğŸ‡ª-ğŸ‡­ğŸ‡°-ğŸ‡³ğŸ‡·-ğŸ‡¹ğŸ‡¼ğŸ‡¾]|ğŸ‡¶ğŸ‡¦|ğŸ‡·[ğŸ‡ªğŸ‡´ğŸ‡¸ğŸ‡ºğŸ‡¼]|ğŸ‡¸[ğŸ‡¦-ğŸ‡ªğŸ‡¬-ğŸ‡´ğŸ‡·-ğŸ‡¹ğŸ‡»ğŸ‡½-ğŸ‡¿]|ğŸ‡¹[ğŸ‡¦ğŸ‡¨ğŸ‡©ğŸ‡«-ğŸ‡­ğŸ‡¯-ğŸ‡´ğŸ‡·ğŸ‡¹ğŸ‡»ğŸ‡¼ğŸ‡¿]|ğŸ‡º[ğŸ‡¦ğŸ‡¬ğŸ‡²ğŸ‡³ğŸ‡¸ğŸ‡¾ğŸ‡¿]|ğŸ‡»[ğŸ‡¦ğŸ‡¨ğŸ‡ªğŸ‡¬ğŸ‡®ğŸ‡³ğŸ‡º]|ğŸ‡¼[ğŸ‡«ğŸ‡¸]|ğŸ‡½ğŸ‡°|ğŸ‡¾[ğŸ‡ªğŸ‡¹]|ğŸ‡¿[ğŸ‡¦ğŸ‡²ğŸ‡¼]|ğŸ„(?:â€ğŸŸ«)?|ğŸ‹(?:â€ğŸŸ©)?|[ğŸƒğŸš¶ğŸ§](?:â€(?:[â™€â™‚]ï¸(?:â€â¡ï¸)?|â¡ï¸)|[ğŸ»-ğŸ¿](?:â€(?:[â™€â™‚]ï¸(?:â€â¡ï¸)?|â¡ï¸))?)?|[ğŸ„ğŸŠğŸ‘®ğŸ‘°ğŸ‘±ğŸ‘³ğŸ‘·ğŸ’ğŸ’‚ğŸ’†ğŸ’‡ğŸ™…-ğŸ™‡ğŸ™‹ğŸ™ğŸ™ğŸš£ğŸš´ğŸšµğŸ¤¦ğŸ¤µğŸ¤·-ğŸ¤¹ğŸ¤½ğŸ¤¾ğŸ¦¸ğŸ¦¹ğŸ§ğŸ§ğŸ§”ğŸ§–-ğŸ§](?:â€[â™€â™‚]ï¸|[ğŸ»-ğŸ¿](?:â€[â™€â™‚]ï¸)?)?|ğŸ³(?:ï¸â€(?:âš§ï¸|ğŸŒˆ))?|ğŸ´(?:â€â˜ ï¸|ó §(?:ó ¢(?:ó ¥ó ®ó §|ó ³ó £ó ´)ó ¿)?)?|ğŸˆ(?:â€â¬›)?|ğŸ•(?:â€ğŸ¦º)?|ğŸ¦(?:â€[â¬›ğŸ”¥])?|ğŸ»(?:â€â„ï¸)?|ğŸ‘(?:ï¸â€ğŸ—¨ï¸)?|ğŸ‘¨(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ‘¨|ğŸ‘¦(?:â€ğŸ‘¦)?|ğŸ‘§(?:â€[ğŸ‘¦ğŸ‘§])?|[ğŸ‘¨ğŸ‘©]â€(?:ğŸ‘¦(?:â€ğŸ‘¦)?|ğŸ‘§(?:â€[ğŸ‘¦ğŸ‘§])?)|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³])|ğŸ»(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ‘¨[ğŸ»-ğŸ¿]|ğŸ¤â€ğŸ‘¨[ğŸ¼-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¼(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ‘¨[ğŸ»-ğŸ¿]|ğŸ¤â€ğŸ‘¨[ğŸ»ğŸ½-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ½(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ‘¨[ğŸ»-ğŸ¿]|ğŸ¤â€ğŸ‘¨[ğŸ»ğŸ¼ğŸ¾ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¾(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ‘¨[ğŸ»-ğŸ¿]|ğŸ¤â€ğŸ‘¨[ğŸ»-ğŸ½ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¿(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ‘¨[ğŸ»-ğŸ¿]|ğŸ¤â€ğŸ‘¨[ğŸ»-ğŸ¾]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?)?|ğŸ‘©(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:[ğŸ‘¨ğŸ‘©]|ğŸ’‹â€[ğŸ‘¨ğŸ‘©])|ğŸ‘¦(?:â€ğŸ‘¦)?|ğŸ‘§(?:â€[ğŸ‘¦ğŸ‘§])?|ğŸ‘©â€(?:ğŸ‘¦(?:â€ğŸ‘¦)?|ğŸ‘§(?:â€[ğŸ‘¦ğŸ‘§])?)|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³])|ğŸ»(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?[ğŸ‘¨ğŸ‘©][ğŸ»-ğŸ¿]|ğŸ¤â€[ğŸ‘¨ğŸ‘©][ğŸ¼-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¼(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?[ğŸ‘¨ğŸ‘©][ğŸ»-ğŸ¿]|ğŸ¤â€[ğŸ‘¨ğŸ‘©][ğŸ»ğŸ½-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ½(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?[ğŸ‘¨ğŸ‘©][ğŸ»-ğŸ¿]|ğŸ¤â€[ğŸ‘¨ğŸ‘©][ğŸ»ğŸ¼ğŸ¾ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¾(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?[ğŸ‘¨ğŸ‘©][ğŸ»-ğŸ¿]|ğŸ¤â€[ğŸ‘¨ğŸ‘©][ğŸ»-ğŸ½ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¿(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?[ğŸ‘¨ğŸ‘©][ğŸ»-ğŸ¿]|ğŸ¤â€[ğŸ‘¨ğŸ‘©][ğŸ»-ğŸ¾]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?)?|[ğŸ‘¯ğŸ¤¼ğŸ§ğŸ§Ÿ](?:â€[â™€â™‚]ï¸)?|ğŸ˜®(?:â€ğŸ’¨)?|ğŸ˜µ(?:â€ğŸ’«)?|ğŸ˜¶(?:â€ğŸŒ«ï¸)?|ğŸ™‚(?:â€[â†”â†•]ï¸)?|ğŸ§‘(?:â€(?:[âš•âš–âœˆ]ï¸|ğŸ¤â€ğŸ§‘|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ„ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]|(?:ğŸ§‘â€)?ğŸ§’(?:â€ğŸ§’)?)|ğŸ»(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ§‘[ğŸ¼-ğŸ¿]|ğŸ¤â€ğŸ§‘[ğŸ»-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ„ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¼(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ§‘[ğŸ»ğŸ½-ğŸ¿]|ğŸ¤â€ğŸ§‘[ğŸ»-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ„ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ½(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ§‘[ğŸ»ğŸ¼ğŸ¾ğŸ¿]|ğŸ¤â€ğŸ§‘[ğŸ»-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ„ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¾(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ§‘[ğŸ»-ğŸ½ğŸ¿]|ğŸ¤â€ğŸ§‘[ğŸ»-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ„ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?|ğŸ¿(?:â€(?:[âš•âš–âœˆ]ï¸|â¤ï¸â€(?:ğŸ’‹â€)?ğŸ§‘[ğŸ»-ğŸ¾]|ğŸ¤â€ğŸ§‘[ğŸ»-ğŸ¿]|[ğŸ¦¯ğŸ¦¼ğŸ¦½](?:â€â¡ï¸)?|[ğŸŒ¾ğŸ³ğŸ¼ğŸ„ğŸ“ğŸ¤ğŸ¨ğŸ«ğŸ­ğŸ’»ğŸ’¼ğŸ”§ğŸ”¬ğŸš€ğŸš’ğŸ¦°-ğŸ¦³]))?)?|[Â©Â®â€¼â‰â„¢â„¹â†”-â†™â†©â†ªâŒšâŒ›âŒ¨ââ©-â³â¸-âºâ“‚â–ªâ–«â–¶â—€â—»-â—¾â˜€-â˜„â˜â˜‘â˜”â˜•â˜˜â˜ â˜¢â˜£â˜¦â˜ªâ˜®â˜¯â˜¸-â˜ºâ™€â™‚â™ˆ-â™“â™Ÿâ™ â™£â™¥â™¦â™¨â™»â™¾â™¿âš’-âš—âš™âš›âšœâš âš¡âš§âšªâš«âš°âš±âš½âš¾â›„â›…â›ˆâ›â›â›‘â›”â›©â›ªâ›°-â›µâ›·â›¸â›ºâ›½âœ‚âœ…âœˆâœ‰âœâœ’âœ”âœ–âœâœ¡âœ¨âœ³âœ´â„â‡âŒââ“-â•â—â£â•-â—â¡â°â¿â¤´â¤µâ¬…-â¬‡â¬›â¬œâ­â­•ã€°ã€½ãŠ—ãŠ™ğŸ€„ğŸƒğŸ…°ğŸ…±ğŸ…¾ğŸ…¿ğŸ†ğŸ†‘-ğŸ†šğŸˆğŸˆ‚ğŸˆšğŸˆ¯ğŸˆ²-ğŸˆºğŸ‰ğŸ‰‘ğŸŒ€-ğŸŒ¡ğŸŒ¤-ğŸƒğŸ…-ğŸŠğŸŒ-ğŸ„ğŸ†-ğŸ“ğŸ–ğŸ—ğŸ™-ğŸ›ğŸ-ğŸğŸ…ğŸ†ğŸˆğŸ‰ğŸ-ğŸ°ğŸµğŸ·-ğŸ‡ğŸ‰-ğŸ”ğŸ–-ğŸ¥ğŸ§-ğŸºğŸ¼-ğŸ‘€ğŸ‘„ğŸ‘…ğŸ‘‘-ğŸ‘¥ğŸ‘ªğŸ‘¹-ğŸ‘»ğŸ‘½-ğŸ’€ğŸ’„ğŸ’ˆ-ğŸ’ğŸ’ğŸ’’-ğŸ’©ğŸ’«-ğŸ“½ğŸ“¿-ğŸ”½ğŸ•‰-ğŸ•ğŸ•-ğŸ•§ğŸ•¯ğŸ•°ğŸ•³ğŸ•¶-ğŸ•¹ğŸ–‡ğŸ–Š-ğŸ–ğŸ–¤ğŸ–¥ğŸ–¨ğŸ–±ğŸ–²ğŸ–¼ğŸ—‚-ğŸ—„ğŸ—‘-ğŸ—“ğŸ—œ-ğŸ—ğŸ—¡ğŸ—£ğŸ—¨ğŸ—¯ğŸ—³ğŸ—º-ğŸ˜­ğŸ˜¯-ğŸ˜´ğŸ˜·-ğŸ™ğŸ™ƒğŸ™„ğŸ™ˆ-ğŸ™ŠğŸš€-ğŸš¢ğŸš¤-ğŸš³ğŸš·-ğŸš¿ğŸ›-ğŸ›…ğŸ›‹ğŸ›-ğŸ›’ğŸ›•-ğŸ›—ğŸ›œ-ğŸ›¥ğŸ›©ğŸ›«ğŸ›¬ğŸ›°ğŸ›³-ğŸ›¼ğŸŸ -ğŸŸ«ğŸŸ°ğŸ¤ğŸ¤ğŸ¤-ğŸ¤—ğŸ¤ -ğŸ¤¥ğŸ¤§-ğŸ¤¯ğŸ¤ºğŸ¤¿-ğŸ¥…ğŸ¥‡-ğŸ¥¶ğŸ¥¸-ğŸ¦´ğŸ¦·ğŸ¦ºğŸ¦¼-ğŸ§ŒğŸ§ğŸ§ -ğŸ§¿ğŸ©°-ğŸ©¼ğŸª€-ğŸªˆğŸª-ğŸª½ğŸª¿-ğŸ«‚ğŸ«-ğŸ«›ğŸ« -ğŸ«¨]|ğŸ«±(?:ğŸ»(?:â€ğŸ«²[ğŸ¼-ğŸ¿])?|ğŸ¼(?:â€ğŸ«²[ğŸ»ğŸ½-ğŸ¿])?|ğŸ½(?:â€ğŸ«²[ğŸ»ğŸ¼ğŸ¾ğŸ¿])?|ğŸ¾(?:â€ğŸ«²[ğŸ»-ğŸ½ğŸ¿])?|ğŸ¿(?:â€ğŸ«²[ğŸ»-ğŸ¾])?)?)+"
        text = re.sub(emojis, "", text)


        #unused
        # accents = re.compile(r'[\u064b-\u0652\u0640]') # harakaat and tatweel (kashida) to remove

        # arabic_punc= re.compile(r'[\u0621-\u063A\u0641-\u064A\d+]+') # Keep only Arabic letters/do not remove numbers
        # text=' '.join(arabic_punc.findall(accents.sub('',text)))
        text = text.strip()
        return text


def wrap(text: str):
    """
    Print strings line-wrapped.

    Parameters:
    - text (str): The text you want to print.
    """

    wrapped_text = textwrap.fill(text, width=80) #text is the object which you want to print
    print(wrapped_text)


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clef.utils.data_loading import load_datasets\n",
    "from clef.utils.data_loading import write_trec_format_output\n",
    "from clef.retrieval.retrieve import retrieve_evidence\n",
    "\n",
    "train, dev = load_datasets(preprocess=True, add_author_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "import json\n",
    "\n",
    "impl_wait_time = 10\n",
    "\n",
    "def scrape_author_info(twitter_url: str, driver: webdriver.Chrome):\n",
    "    # Open Twitter URL\n",
    "    driver.get(twitter_url)\n",
    "\n",
    "    # Fetch user's account name and bio\n",
    "    account_name = driver.find_element(By.XPATH, '//div[contains(@class,\"r-1wbh5a2\")]//span//span').text\n",
    "\n",
    "    # some users don't have a bio\n",
    "    driver.implicitly_wait(0.1)\n",
    "    bio = ''\n",
    "    try:\n",
    "        bio = driver.find_element(By.XPATH, '//div[contains(@data-testid,\"UserDescription\")]').text\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    driver.implicitly_wait(impl_wait_time)\n",
    "        \n",
    "    # strip newlines\n",
    "    bio = re.sub(r\"\\n\", \" \", bio)\n",
    "\n",
    "    return (account_name, bio)\n",
    "\n",
    "\n",
    "def translate_info(text: str, driver: webdriver.Chrome):\n",
    "    # # Navigate to Google Translate\n",
    "    driver.get(\"https://translate.google.com\")\n",
    "\n",
    "    # # Accept consent form\n",
    "    # button = driver.find_element(By.XPATH, '//button[@aria-label=\"Reject all\"]')\n",
    "    # button.click()\n",
    "\n",
    "    # Enter the bio into the translate text box\n",
    "    input_box = driver.find_element(By.CLASS_NAME, \"er8xn\")\n",
    "    input_box.send_keys(text)\n",
    "\n",
    "    # Retrieve the translated text\n",
    "    translated = driver.find_element(By.XPATH, '//span[@jsname=\"jqKxS\"]').text\n",
    "\n",
    "    # strip newlines\n",
    "    translated = re.sub(r\"\\n\", \" \", translated)\n",
    "\n",
    "    return translated\n",
    "\n",
    "def get_author_info_dict(account_list, driver, fp):\n",
    "    author_info_by_account = {}\n",
    "\n",
    "    # setup empty dict\n",
    "    for account in account_list:\n",
    "        author_info_by_account[account.strip()] = {'name': '', 'bio': '', 'translated_name': '', 'translated_bio': '', 'error': ''}\n",
    "\n",
    "    # get twitter info\n",
    "    for i, account_url in enumerate(author_info_by_account.keys()):\n",
    "        try:\n",
    "            name, bio = scrape_author_info(account_url, driver)\n",
    "            name = re.sub(r\"@[\\w]*\", \"\", name)\n",
    "            if name == '':\n",
    "                print(f'[ERROR] couldn\\'t retrieve info for account {account_url}')\n",
    "                author_info_by_account[account_url]['error'] = 'user account unreachable;'\n",
    "            author_info_by_account[account_url]['name'] = name\n",
    "            author_info_by_account[account_url]['bio'] = bio\n",
    "        except NoSuchElementException:\n",
    "            print(f'[ERROR] couldn\\'t retrieve info for account {account_url}')\n",
    "            author_info_by_account[account_url]['error'] = 'user account unreachable;'\n",
    "\n",
    "    # write dict to file\n",
    "    with open(fp, 'w') as file:\n",
    "        json.dump(author_info_by_account, file, indent=4, sort_keys=False)\n",
    "        print(f'wrote dict with {len(author_info_by_account)} entries to {fp}')\n",
    "        \n",
    "    return author_info_by_account\n",
    "\n",
    "def translate_dict(author_info_by_account, driver, fp):\n",
    "    for i, account_url in enumerate(author_info_by_account.keys()):\n",
    "        try:\n",
    "            name = author_info_by_account[account_url]['name']\n",
    "            bio = author_info_by_account[account_url]['bio']\n",
    "            if name and bio:\n",
    "                author_info_by_account[account_url]['translated_name'] = translate_info(name, driver)\n",
    "                author_info_by_account[account_url]['translated_bio'] = translate_info(bio, driver)\n",
    "        except NoSuchElementException:\n",
    "            print(f'[ERROR] couldn\\'t translate info for account {account_url}')\n",
    "            author_info_by_account[account_url]['error'] += 'could not translate;'\n",
    "\n",
    "    # write final dict to file\n",
    "    with open(fp, 'w') as file:\n",
    "        json.dump(author_info_by_account, file, indent=4, sort_keys=False)\n",
    "        print(f'wrote dict with {len(author_info_by_account)} entries to {fp}')\n",
    "    \n",
    "    return author_info_by_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Selenium\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(impl_wait_time) # set default waiting strategy\n",
    "driver.get(\"https://translate.google.com\")\n",
    "\n",
    "# Accept consent form\n",
    "button = driver.find_element(By.XPATH, '//button[@aria-label=\"Reject all\"]')\n",
    "button.click()\n",
    "\n",
    "driver.get(\"https://twitter.com/login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = []\n",
    "for item in dev:\n",
    "    for account, id, tweet, in item['timeline']:\n",
    "        accounts += [account]\n",
    "\n",
    "accounts = list(set(accounts))\n",
    "# accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_out = 'author-data.json'\n",
    "info = get_author_info_dict(accounts, driver, fp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter cuts me off at about 100 requests, so we go again for the last few\n",
    "# could maybe be fixed using sleep waiting\n",
    "missing = ['https://twitter.com/TrablusBe',\n",
    "'https://twitter.com/Hakomitna',\n",
    "'https://twitter.com/KasbahTn',\n",
    "'https://twitter.com/hazemaq',\n",
    "'https://twitter.com/SerajSat',\n",
    "'https://twitter.com/Moshir_Almasry',\n",
    "'https://twitter.com/mosa_abumarzook',\n",
    "'https://twitter.com/MofaQatar_AR',\n",
    "'https://twitter.com/ofirgendelman',\n",
    "'https://twitter.com/pmofa',\n",
    "'https://twitter.com/ibrahimmilhim',\n",
    "'https://twitter.com/HananBalkhy',\n",
    "'https://twitter.com/UNNewsArabic',\n",
    "'https://twitter.com/OmanEmbassydoha',\n",
    "'https://twitter.com/FMofOman',\n",
    "'https://twitter.com/Oman_GC',]\n",
    "\n",
    "fp_out = 'missing.json'\n",
    "\n",
    "missinginfo = get_author_info_dict(missing, driver, fp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def merge_dicts(d1, d2):\n",
    "    \"\"\"\n",
    "    Merge two dictionaries with dictionary values.\n",
    "    In case of common keys, their dictionary values are also merged,\n",
    "    with values from d2 taking precedence in case of key conflicts.\n",
    "    \"\"\"\n",
    "    merged_dict = {**d1}  # Start with the keys and values from d1\n",
    "    \n",
    "    for key, value in d2.items():\n",
    "        if key in d1 and isinstance(d1[key], dict) and isinstance(value, dict):\n",
    "            # If the key is common and both values are dictionaries, merge them\n",
    "            merged_dict[key] = merge_dicts(d1[key], value)\n",
    "        else:\n",
    "            # Otherwise, use the value from d2, overriding any existing value in d1\n",
    "            merged_dict[key] = value\n",
    "    \n",
    "    return merged_dict\n",
    "\n",
    "def load_json_files(file_paths):\n",
    "    \"\"\"Load multiple JSON files and return their contents as dictionaries.\"\"\"\n",
    "    data = []\n",
    "    for path in file_paths:\n",
    "        with open(path, 'r') as file:\n",
    "            data.append(json.load(file))\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "json_files = ['author-data.json', 'missing.json']\n",
    "dicts = load_json_files(json_files)\n",
    "\n",
    "final_data = merge_dicts(dicts[0], dicts[1])\n",
    "\n",
    "fp = 'combined.json'\n",
    "with open(fp, 'w') as file:\n",
    "    json.dump(final_data, file, indent=4, sort_keys=False)\n",
    "    print(f'wrote dict with {len(final_data)} entries to {fp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 'combined.json'\n",
    "with open(fp, 'r') as file:\n",
    "    info = json.load(file)\n",
    "# info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_out = 'author-data-translated.json'\n",
    "info_with_translation = translate_dict(info, driver, fp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

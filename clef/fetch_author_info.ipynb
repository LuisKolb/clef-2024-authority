{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 96 training json lines and 32 dev json lines.\n"
     ]
    }
   ],
   "source": [
    "from clef.utils.data_loading import load_datasets\n",
    "\n",
    "train, dev = load_datasets(preprocess=False, add_author_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "impl_wait_time = 10\n",
    "\n",
    "def scrape_author_info(twitter_url: str, driver: webdriver.Chrome):\n",
    "    # Open Twitter URL\n",
    "    driver.get(twitter_url)\n",
    "\n",
    "    # Fetch user's account name and bio\n",
    "    account_name = driver.find_element(By.XPATH, '//div[contains(@class,\"r-1wbh5a2\")]//span//span').text\n",
    "\n",
    "    # some users don't have a bio\n",
    "    driver.implicitly_wait(0.1)\n",
    "    bio = ''\n",
    "    try:\n",
    "        bio = driver.find_element(By.XPATH, '//div[contains(@data-testid,\"UserDescription\")]').text\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    driver.implicitly_wait(impl_wait_time)\n",
    "    \n",
    "    return (account_name, bio)\n",
    "\n",
    "\n",
    "def translate_text(text: str, driver: webdriver.Chrome):\n",
    "    # Enter the text into the translate text box\n",
    "    input_box = driver.find_element(By.CLASS_NAME, \"er8xn\")\n",
    "    input_box.send_keys(text)\n",
    "\n",
    "    # Retrieve the translated text\n",
    "    translated = driver.find_element(By.XPATH, '//span[@jsname=\"jqKxS\"]').text\n",
    "\n",
    "    # Clear the textbox\n",
    "    btn_clear = driver.find_element(By.XPATH, '//button[@aria-label=\"Clear source text\"]')\n",
    "    btn_clear.click()\n",
    "\n",
    "    return translated\n",
    "\n",
    "\n",
    "def twitter_data_dict(account_list, driver, fp):\n",
    "    author_info_by_account = {}\n",
    "\n",
    "    # setup empty dict\n",
    "    for account in account_list:\n",
    "        author_info_by_account[account.strip()] = {'name': '', 'bio': '', 'translated_name': '', 'translated_bio': '', 'error': ''}\n",
    "\n",
    "    # get twitter info\n",
    "    for i, account_url in enumerate(author_info_by_account.keys()):\n",
    "        try:\n",
    "            time.sleep(10)\n",
    "            name, bio = scrape_author_info(account_url, driver)\n",
    "            name = re.sub(r\"@[\\w]*\", \"\", name)\n",
    "            bio = re.sub(r\"\\n\", \" \", bio)\n",
    "            \n",
    "            if name == '':\n",
    "                print(f'[ERROR] couldn\\'t retrieve info for account {account_url}')\n",
    "                author_info_by_account[account_url]['error'] = 'user account unreachable;'\n",
    "            \n",
    "            author_info_by_account[account_url]['name'] = name\n",
    "            author_info_by_account[account_url]['bio'] = bio\n",
    "        except NoSuchElementException:\n",
    "            print(f'[ERROR] could not retrieve info for account {account_url}')\n",
    "            author_info_by_account[account_url]['error'] += 'user account unreachable;'\n",
    "\n",
    "    # write dict to file\n",
    "    with open(fp, 'w') as file:\n",
    "        json.dump(author_info_by_account, file, indent=4, sort_keys=False)\n",
    "        print(f'wrote dict with {len(author_info_by_account)} entries to {fp}')\n",
    "        \n",
    "    return author_info_by_account\n",
    "\n",
    "\n",
    "def get_session_translate():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(impl_wait_time) # set default waiting strategy\n",
    "    \n",
    "    driver.get(\"https://translate.google.com\")\n",
    "\n",
    "    # Accept consent form\n",
    "    button = driver.find_element(By.XPATH, '//button[@aria-label=\"Reject all\"]')\n",
    "    button.click()\n",
    "\n",
    "    driver.get(\"https://translate.google.com\")\n",
    "    return driver\n",
    "\n",
    "\n",
    "def translate_dict(author_info_by_account, fp):\n",
    "    driver = get_session_translate()\n",
    "    # Navigate to Google Translate\n",
    "    driver.get(\"https://translate.google.com\")\n",
    "    for i, account_url in enumerate(author_info_by_account.keys()):\n",
    "        try:\n",
    "            name = author_info_by_account[account_url]['name']\n",
    "            bio = author_info_by_account[account_url]['bio']\n",
    "            if name and bio:\n",
    "                author_info_by_account[account_url]['translated_name'] = translate_text(name, driver)\n",
    "                author_info_by_account[account_url]['translated_bio'] = translate_text(bio, driver)\n",
    "        except NoSuchElementException:\n",
    "            print(f'[ERROR] couldn\\'t translate info for account {account_url}, retrying with new session...')\n",
    "            # author_info_by_account[account_url]['error'] += 'could not translate;'\n",
    "\n",
    "            # restart driver\n",
    "            driver.quit()\n",
    "            driver = get_session_translate()\n",
    "\n",
    "            # retry with new driver\n",
    "            name = author_info_by_account[account_url]['name']\n",
    "            bio = author_info_by_account[account_url]['bio']\n",
    "            if name and bio:\n",
    "                author_info_by_account[account_url]['translated_name'] = translate_text(name, driver)\n",
    "                author_info_by_account[account_url]['translated_bio'] = translate_text(bio, driver)\n",
    "\n",
    "    # write final dict to file\n",
    "    with open(fp, 'w') as file:\n",
    "        json.dump(author_info_by_account, file, indent=4, sort_keys=False)\n",
    "        print(f'wrote dict with {len(author_info_by_account)} entries to {fp}')\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    return author_info_by_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## obtain twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts = []\n",
    "for item in dev:\n",
    "    for account, id, tweet, in item['timeline']:\n",
    "        accounts += [account]\n",
    "\n",
    "accounts = list(set(accounts))\n",
    "len(accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Selenium\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(impl_wait_time) # set default waiting strategy\n",
    "\n",
    "driver.get(\"https://twitter.com/login\")\n",
    "# login to account manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] couldn't retrieve info for account https://twitter.com/SerajSat\n",
      "[ERROR] couldn't retrieve info for account https://twitter.com/hazemaq\n",
      "[ERROR] couldn't retrieve info for account https://twitter.com/TrablusBe\n",
      "[ERROR] couldn't retrieve info for account https://twitter.com/KasbahTn\n",
      "[ERROR] couldn't retrieve info for account https://twitter.com/Moshir_Almasry\n",
      "[ERROR] couldn't retrieve info for account https://twitter.com/mosa_abumarzook\n",
      "wrote dict with 108 entries to data/author-data.json\n"
     ]
    }
   ],
   "source": [
    "fp_out = 'data/author-data.json'\n",
    "info = twitter_data_dict(accounts, driver, fp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## translate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 'data/author-data.json'\n",
    "with open(fp, 'r') as file:\n",
    "    info = json.load(file)\n",
    "# info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] couldn't translate info for account https://twitter.com/TunisieDiplo, retrying with new session...\n",
      "[ERROR] couldn't translate info for account https://twitter.com/Nahar_Az, retrying with new session...\n",
      "wrote dict with 108 entries to data/author-data-translated.json\n"
     ]
    }
   ],
   "source": [
    "fp_out = 'data/author-data-translated.json'\n",
    "info_with_translation = translate_dict(info, fp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## close the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter cuts me off at about 100 requests, so we go again for the last few\n",
    "# could maybe be fixed using sleep waiting\n",
    "missing = ['https://twitter.com/TrablusBe',\n",
    "'https://twitter.com/Hakomitna',\n",
    "'https://twitter.com/KasbahTn',\n",
    "'https://twitter.com/hazemaq',\n",
    "'https://twitter.com/SerajSat',\n",
    "'https://twitter.com/Moshir_Almasry',\n",
    "'https://twitter.com/mosa_abumarzook',\n",
    "'https://twitter.com/MofaQatar_AR',\n",
    "'https://twitter.com/ofirgendelman',\n",
    "'https://twitter.com/pmofa',\n",
    "'https://twitter.com/ibrahimmilhim',\n",
    "'https://twitter.com/HananBalkhy',\n",
    "'https://twitter.com/UNNewsArabic',\n",
    "'https://twitter.com/OmanEmbassydoha',\n",
    "'https://twitter.com/FMofOman',\n",
    "'https://twitter.com/Oman_GC',]\n",
    "\n",
    "fp_out = 'data/missing.json'\n",
    "\n",
    "missinginfo = twitter_data_dict(missing, driver, fp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "def merge_dicts(d1, d2):\n",
    "    \"\"\"\n",
    "    Merge two dictionaries with dictionary values.\n",
    "    In case of common keys, their dictionary values are also merged,\n",
    "    with values from d2 taking precedence in case of key conflicts.\n",
    "    \"\"\"\n",
    "    merged_dict = {**d1}  # Start with the keys and values from d1\n",
    "    \n",
    "    for key, value in d2.items():\n",
    "        if key in d1 and isinstance(d1[key], dict) and isinstance(value, dict):\n",
    "            # If the key is common and both values are dictionaries, merge them\n",
    "            merged_dict[key] = merge_dicts(d1[key], value)\n",
    "        else:\n",
    "            # Otherwise, use the value from d2, overriding any existing value in d1\n",
    "            merged_dict[key] = value\n",
    "    \n",
    "    return merged_dict\n",
    "\n",
    "def load_json_files(file_paths):\n",
    "    \"\"\"Load multiple JSON files and return their contents as dictionaries.\"\"\"\n",
    "    data = []\n",
    "    for path in file_paths:\n",
    "        with open(path, 'r') as file:\n",
    "            data.append(json.load(file))\n",
    "    return data\n",
    "\n",
    "json_files = ['data/author-data.json', 'data/missing.json']\n",
    "dicts = load_json_files(json_files)\n",
    "\n",
    "final_data = merge_dicts(dicts[0], dicts[1])\n",
    "\n",
    "fp = 'combined.json'\n",
    "with open(fp, 'w') as file:\n",
    "    json.dump(final_data, file, indent=4, sort_keys=False)\n",
    "    print(f'wrote dict with {len(final_data)} entries to {fp}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

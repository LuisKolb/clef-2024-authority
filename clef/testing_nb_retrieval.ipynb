{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 96 training json objects and 32 dev objects\n"
     ]
    }
   ],
   "source": [
    "from utils import load_rumors_from_jsonl\n",
    "import os\n",
    "\n",
    "out_dir = './temp-data'\n",
    "\n",
    "clef_path = '../clef2024-checkthat-lab/task5'\n",
    "data_path = os.path.join(clef_path, 'data')\n",
    "\n",
    "filepath_train = os.path.join(data_path, 'English_train.json')\n",
    "filepath_dev = os.path.join(data_path, 'English_dev.json')\n",
    "\n",
    "train_jsons = load_rumors_from_jsonl(filepath_train)\n",
    "dev_jsons = load_rumors_from_jsonl(filepath_dev)\n",
    "\n",
    "print(f'loaded {len(train_jsons)} training json objects and {len(dev_jsons)} dev objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine all training data, maybe to use for a global index?\n",
    "# # but we need to do \"zero-shot\" retrieval...\n",
    "# all_timeline_tweets = {}\n",
    "# duplicates = 0\n",
    "\n",
    "# for d in train_jsons:\n",
    "#     for author_url, id, text in d['timeline']:\n",
    "#         if id not in all_timeline_tweets:\n",
    "#             all_timeline_tweets[id] = {'author_url': author_url, 'text': text }\n",
    "#         else:\n",
    "#             duplicates += 1\n",
    "\n",
    "# print(len(all_timeline_tweets.keys()))\n",
    "# print(duplicates)\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open('temp-data/eng-train.jsonl', mode='w') as file:\n",
    "#     file.write('')\n",
    "\n",
    "# with open('temp-data/eng-train.jsonl', mode='a', encoding='utf8') as file:\n",
    "#     for id in all_timeline_tweets:\n",
    "#         o = {'id': id, 'contents': all_timeline_tweets[id]['text']}\n",
    "#         file.write(json.dumps(o) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyserini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "# if you get the error \"NameError: name '_C' is not defined\" --> restart the Jupyter Kernel\n",
    "\n",
    "def searchPyserini(query,\n",
    "                   timeline,\n",
    "                   k = 5,\n",
    "                   temp_dir = 'temp-data-dir',\n",
    "                   index = 'temp-data-dir/index_timeline_dynamic'):\n",
    "    \n",
    "    # ensure \"working directory\" exists (where we store intermediate data like the dynamic index that will be quered later)\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.mkdir(temp_dir)\n",
    "\n",
    "    # set up \"dynamic\" (= temporary) index using timeline data\n",
    "    dynamic_idx_filename = 'eng-train-dynamic.jsonl'\n",
    "    with open(os.path.join(temp_dir, dynamic_idx_filename), mode='w', encoding='utf8') as file:\n",
    "        for tweet in timeline:\n",
    "            id = tweet[1]\n",
    "            text = tweet[2]\n",
    "            file.write(json.dumps({'id': id, 'contents': text}) + '\\n')\n",
    "    \n",
    "    # ensure index directory exists and is empty\n",
    "    if os.path.exists(index):\n",
    "        for filename in os.listdir(index):\n",
    "            if os.path.isfile(os.path.join(index, filename)):\n",
    "                os.remove(os.path.join(index, filename))\n",
    "    else:\n",
    "        os.mkdir(index)\n",
    "\n",
    "    # set up pyserini command since python embeddable is not out yet\n",
    "    nthreads = 1\n",
    "    command = f'python -m pyserini.index.lucene ' \\\n",
    "    f'-input {temp_dir} ' \\\n",
    "    f'-collection JsonCollection ' \\\n",
    "    f'-generator DefaultLuceneDocumentGenerator ' \\\n",
    "    f'-index {index} ' \\\n",
    "    f'-threads {nthreads} ' \\\n",
    "    f'-storePositions ' \\\n",
    "    f'-storeDocvectors ' \\\n",
    "    f'-storeRaw ' \\\n",
    "    f'-language en'\n",
    "\n",
    "    result = subprocess.run(command, capture_output=True)\n",
    "\n",
    "    # load searcher from index directoy\n",
    "    searcher = LuceneSearcher(index)\n",
    "    hits = searcher.search(query)\n",
    "\n",
    "    ranked_tuples = []\n",
    "\n",
    "    for hit in hits:\n",
    "        doc = searcher.doc(hit.docid)\n",
    "        json_doc = json.loads(doc.raw())\n",
    "\n",
    "        ranked_tuples += [(hit.docid, hit.score, json_doc[\"contents\"])]\n",
    "\n",
    "        # wrap(f'{i+1:2} {hits[i].docid:4} {hits[i].score:.5f}\\n{json_doc[\"contents\"]}')\n",
    "\n",
    "    return ranked_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1590400068208988160',\n",
       "  23.554899215698242,\n",
       "  'After circulating news that the Governor of the Bank of Lebanon, Riad Salameh, had announced to NBN about raising the value of the dollar and raising the ceiling on banking withdrawals, the NBN channel denies the validity of this information that is being circulated, citing the channel, and confirms that there is no truth to it on this subject. https://t.co/oIF6QW9rTB https://t.co/ZRlfbccr2y'),\n",
       " ('1591489851106668544',\n",
       "  15.838800430297852,\n",
       "  'Raising the exchange rate of the customs dollar, the TVA, and withdrawals from banks... What are its repercussions and results? Is there economic and financial stability in light of the current political chaos? Report: Rasha Al-Zein Hashem https://t.co/Q7nJM2Dvdt @rashazeinnbn'),\n",
       " ('1589949764107665409',\n",
       "  9.809499740600586,\n",
       "  \"Turkish Minister of Energy: #Turkey's purchases of natural gas from #Russia have begun to be partially paid in Russian rubles.. The share of payments in local currency in exchange for energy imports from Russia will increase in the coming months https://t.co/Vn5JeaAAsl\"),\n",
       " ('1590995361132212224',\n",
       "  9.197500228881836,\n",
       "  'Russian Foreign Ministry: The Russian-American advisory committee on the START nuclear treaty will meet at the end of the month in Cairo'),\n",
       " ('1591404278996168705',\n",
       "  9.040399551391602,\n",
       "  '“Regie” continues to receive tobacco crops from farmers in dollars https://t.co/PV1S3TAp2E https://t.co/IJhvfgbFdF'),\n",
       " ('1589672879981199360',\n",
       "  8.815299987792969,\n",
       "  'The #Bank_of_Lebanon announced that “the trading volume on the Sayrafa platform for today amounted to 25 million US dollars at a rate of 30,100 Lebanese pounds per dollar, according to the exchange rates of operations carried out by banks and exchange institutions on the platform.” https://t.co/HUbgu9pjQd \"'),\n",
       " ('1590254347375386624',\n",
       "  8.592599868774414,\n",
       "  'Aid to combat cholera arrives from #Egypt.. Al-Abyad: It will be distributed to hospitals starting tomorrow https://t.co/uqMOnv0rxD https://t.co/VIp1dllt0i'),\n",
       " ('1589567484746952705',\n",
       "  8.576199531555176,\n",
       "  'Urgent - The regional administration in #Zaporozhye announces the start of trading in the Russian ruble instead of the Ukrainian currency early next January'),\n",
       " ('1591021981386051584',\n",
       "  8.42140007019043,\n",
       "  'Reuters quoted the Russian Ministry of Defense today as saying that it had completed the withdrawal of forces from the western bank of the Dnipro River in the Kherson region in southern #Ukraine https://t.co/YP81QalsPT.'),\n",
       " ('1589654877890019331',\n",
       "  8.149399757385254,\n",
       "  'The exchange rate of the #dollar rose on the black market, as it touched the threshold of 39,000 liras, recording 38,900 liras per dollar.')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAS FOUND\t1590400068208988160 After circulating news that the Governor of the Bank of Lebanon, Riad Salameh, had announced to NBN about raising the value of the dollar and raising the ceiling on banking withdrawals, the NBN channel denies the validity of this information that is being circulated, citing the channel, and confirms that there is no truth to it on this subject. https://t.co/oIF6QW9rTB https://t.co/ZRlfbccr2y\n",
      "NOT FOUND\t1590364198462435329 There is no truth to the information being circulated, quoted by the #NBN channel, regarding a statement by the Governor of the Central Bank regarding banking circulars https://t.co/1nnPkPnTfS\n"
     ]
    }
   ],
   "source": [
    "test_rumor = dev_jsons[2]\n",
    "query = test_rumor['rumor']\n",
    "timeline = test_rumor['timeline']\n",
    "\n",
    "ranked_docs = searchPyserini(query, timeline)\n",
    "display(ranked_docs)\n",
    "\n",
    "# simple spot check\n",
    "for evidence in test_rumor['evidence']:\n",
    "    print(f'{\"WAS FOUND\" if evidence[1] in [x[0] for x in ranked_docs] else \"NOT FOUND\"}\\t{evidence[1]} {evidence[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:21<00:00,  2.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('AuRED_142', '1555986659279360001', 1, 4.115900039672852),\n",
       " ('AuRED_142', '1555424541509386240', 2, 2.2701001167297363),\n",
       " ('AuRED_142', '1555495801962614786', 3, 1.1647000312805176),\n",
       " ('AuRED_142', '1554743913197477888', 4, 1.0306999683380127),\n",
       " ('AuRED_142', '1556558220533157890', 5, 0.9453999996185303),\n",
       " ('AuRED_144', '1576137274990858240', 1, 3.260200023651123),\n",
       " ('AuRED_144', '1575937576061501450', 2, 3.212399959564209),\n",
       " ('AuRED_144', '1575169360397996032', 3, 2.446899890899658),\n",
       " ('AuRED_144', '1576132457803710464', 4, 2.2381999492645264),\n",
       " ('AuRED_144', '1574697757662744576', 5, 2.180500030517578),\n",
       " ('AuRED_132', '1590400068208988160', 1, 23.554899215698242),\n",
       " ('AuRED_132', '1591489851106668544', 2, 15.838800430297852),\n",
       " ('AuRED_132', '1589949764107665409', 3, 9.809499740600586),\n",
       " ('AuRED_132', '1590995361132212224', 4, 9.197500228881836),\n",
       " ('AuRED_132', '1591404278996168705', 5, 9.040399551391602),\n",
       " ('AuRED_099', '1234108219544522752', 1, 3.8231000900268555),\n",
       " ('AuRED_099', '1234500742129553408', 2, 2.9516000747680664),\n",
       " ('AuRED_099', '1234778980236058625', 3, 2.651599884033203),\n",
       " ('AuRED_099', '1233762145080369155', 4, 2.6184000968933105),\n",
       " ('AuRED_099', '1234356105532379136', 5, 2.483299970626831),\n",
       " ('AuRED_150', '1584227099706957824', 1, 7.146399974822998),\n",
       " ('AuRED_150', '1584813539629608960', 2, 4.26639986038208),\n",
       " ('AuRED_150', '1584226822107312129', 3, 4.2153000831604),\n",
       " ('AuRED_150', '1585314890247733248', 4, 2.5501999855041504),\n",
       " ('AuRED_150', '1583524837493858304', 5, 2.3304998874664307),\n",
       " ('AuRED_083', '1264830255417696260', 1, 6.875800132751465),\n",
       " ('AuRED_083', '1263446993017475073', 2, 3.1988000869750977),\n",
       " ('AuRED_083', '1263861336582361088', 3, 3.046299934387207),\n",
       " ('AuRED_083', '1263447784440713219', 4, 2.8194000720977783),\n",
       " ('AuRED_083', '1264188072952020993', 5, 2.2167999744415283),\n",
       " ('AuRED_134', '1586378408640012291', 1, 2.0423998832702637),\n",
       " ('AuRED_134', '1585684799649419265', 2, 1.6514999866485596),\n",
       " ('AuRED_134', '1586984258161479681', 3, 1.5216000080108643),\n",
       " ('AuRED_134', '1586758271708405761', 4, 1.510699987411499),\n",
       " ('AuRED_134', '1585925187022868480', 5, 1.2584999799728394),\n",
       " ('AuRED_136', '1579972146201497600', 1, 14.450699806213379),\n",
       " ('AuRED_136', '1580697425907699716', 2, 7.639100074768066),\n",
       " ('AuRED_136', '1578870994831216640', 3, 6.462299823760986),\n",
       " ('AuRED_136', '1580697417267048449', 4, 6.3333001136779785),\n",
       " ('AuRED_136', '1580927705507581953', 5, 5.061999797821045),\n",
       " ('AuRED_154', '1291769381924605952', 1, 9.472599983215332),\n",
       " ('AuRED_154', '1291777104246341632', 2, 4.617599964141846),\n",
       " ('AuRED_154', '1291777108595834880', 3, 2.9405999183654785),\n",
       " ('AuRED_154', '1292810512481292293', 4, 2.517199993133545),\n",
       " ('AuRED_154', '1291676718336544770', 5, 2.401700019836426),\n",
       " ('AuRED_038', '1305252557800058880', 1, 6.114299774169922),\n",
       " ('AuRED_038', '1304348099436064768', 2, 3.7084999084472656),\n",
       " ('AuRED_038', '1305244995054694405', 3, 3.642899990081787),\n",
       " ('AuRED_038', '1305252580336041984', 4, 3.393199920654297),\n",
       " ('AuRED_038', '1304058226741313537', 5, 3.2163000106811523),\n",
       " ('AuRED_086', '1340029347973967875', 1, 6.923600196838379),\n",
       " ('AuRED_086', '1342073003392307201', 2, 6.117300033569336),\n",
       " ('AuRED_086', '1340691512515055616', 3, 5.69379997253418),\n",
       " ('AuRED_086', '1340783645519466506', 4, 5.604499816894531),\n",
       " ('AuRED_086', '1340647804914548736', 5, 5.502299785614014),\n",
       " ('AuRED_160', '1436047075477688324', 1, 3.4084999561309814),\n",
       " ('AuRED_160', '1437391706287132673', 2, 1.4601999521255493),\n",
       " ('AuRED_160', '1437068425902411776', 3, 0.7444000244140625),\n",
       " ('AuRED_064', '1402349143004176384', 1, 14.894100189208984),\n",
       " ('AuRED_064', '1403809077004750849', 2, 13.517499923706055),\n",
       " ('AuRED_064', '1403808985875157004', 3, 12.991900444030762),\n",
       " ('AuRED_064', '1402762092957011978', 4, 12.717300415039062),\n",
       " ('AuRED_064', '1404004717785649152', 5, 10.843799591064453),\n",
       " ('AuRED_127', '1580116641241001984', 1, 20.453800201416016),\n",
       " ('AuRED_127', '1579568507997786113', 2, 2.177999973297119),\n",
       " ('AuRED_127', '1579568814215540736', 3, 1.7103999853134155),\n",
       " ('AuRED_127', '1579568005033635840', 4, 1.37090003490448),\n",
       " ('AuRED_127', '1579071016482938880', 5, 1.1323000192642212),\n",
       " ('AuRED_106', '1558439305508429825', 1, 2.276900053024292),\n",
       " ('AuRED_106', '1558185887925682184', 2, 0.19629999995231628),\n",
       " ('AuRED_106', '1557425893584273412', 3, 0.16050000488758087),\n",
       " ('AuRED_106', '1558098458061541378', 4, 0.15649999678134918),\n",
       " ('AuRED_106', '1558806060391186432', 5, 0.14810000360012054),\n",
       " ('AuRED_109', '1602397782844837901', 1, 6.353499889373779),\n",
       " ('AuRED_109', '1601595184546197504', 2, 1.4953999519348145),\n",
       " ('AuRED_109', '1602376075136438273', 3, 1.2907999753952026),\n",
       " ('AuRED_109', '1603691440063877122', 4, 0.8823000192642212),\n",
       " ('AuRED_109', '1602602516222541828', 5, 0.43540000915527344),\n",
       " ('AuRED_108', '1608878919326760960', 1, 2.472899913787842),\n",
       " ('AuRED_108', '1608041384216330245', 2, 1.8265999555587769),\n",
       " ('AuRED_108', '1610292239917371394', 3, 1.80649995803833),\n",
       " ('AuRED_108', '1609925529867812864', 4, 1.730299949645996),\n",
       " ('AuRED_108', '1607292879638077440', 5, 1.2905999422073364),\n",
       " ('AuRED_104', '1560295846436028419', 1, 7.335100173950195),\n",
       " ('AuRED_104', '1560388696435822594', 2, 2.942500114440918),\n",
       " ('AuRED_104', '1560003056275791873', 3, 2.8160998821258545),\n",
       " ('AuRED_104', '1561013039901597697', 4, 2.757699966430664),\n",
       " ('AuRED_104', '1559914402190692352', 5, 2.7409000396728516),\n",
       " ('AuRED_100', '1592951081705050112', 1, 22.9768009185791),\n",
       " ('AuRED_100', '1592929754822631425', 2, 22.131500244140625),\n",
       " ('AuRED_100', '1592941151727722496', 3, 12.45300006866455),\n",
       " ('AuRED_100', '1592513494301421569', 4, 7.5278000831604),\n",
       " ('AuRED_100', '1592496766351716354', 5, 6.399400234222412),\n",
       " ('AuRED_045', '1407955143774150656', 1, 9.493800163269043),\n",
       " ('AuRED_045', '1408303034027986945', 2, 8.11400032043457),\n",
       " ('AuRED_045', '1408435090418503680', 3, 5.326600074768066),\n",
       " ('AuRED_045', '1410248891770052616', 4, 4.291999816894531),\n",
       " ('AuRED_045', '1409053456514617346', 5, 3.655400037765503),\n",
       " ('AuRED_025', '1399090962744451072', 1, 10.083399772644043),\n",
       " ('AuRED_025', '1398407841795424256', 2, 8.439299583435059),\n",
       " ('AuRED_025', '1398645567048323075', 3, 8.331100463867188),\n",
       " ('AuRED_025', '1397606266076336138', 4, 7.997499942779541),\n",
       " ('AuRED_025', '1398606175881641985', 5, 7.9095001220703125),\n",
       " ('AuRED_026', '1407660793152348161', 1, 7.463500022888184),\n",
       " ('AuRED_026', '1407390739429007360', 2, 7.1442999839782715),\n",
       " ('AuRED_026', '1407006873237213186', 3, 6.0081000328063965),\n",
       " ('AuRED_026', '1408471561288495106', 4, 5.709000110626221),\n",
       " ('AuRED_026', '1408357954957438976', 5, 5.166999816894531),\n",
       " ('AuRED_088', '1325372814854123520', 1, 6.241000175476074),\n",
       " ('AuRED_088', '1324303144927531008', 2, 2.2095999717712402),\n",
       " ('AuRED_088', '1323965946051153921', 3, 1.6988999843597412),\n",
       " ('AuRED_088', '1323961313022873600', 4, 1.3291000127792358),\n",
       " ('AuRED_088', '1323689647202050048', 5, 1.301800012588501),\n",
       " ('AuRED_053', '1428728742906580994', 1, 3.4312000274658203),\n",
       " ('AuRED_053', '1427584202703265795', 2, 2.191200017929077),\n",
       " ('AuRED_053', '1428792611838603267', 3, 2.1911990642547607),\n",
       " ('AuRED_053', '1427282985464864775', 4, 2.0339999198913574),\n",
       " ('AuRED_053', '1428009465937281036', 5, 1.8071000576019287),\n",
       " ('AuRED_046', '1292061275481083907', 1, 8.0802001953125),\n",
       " ('AuRED_046', '1293889313915142144', 2, 7.788700103759766),\n",
       " ('AuRED_046', '1293874721075933187', 3, 7.347099781036377),\n",
       " ('AuRED_046', '1293146838644686854', 4, 4.19320011138916),\n",
       " ('AuRED_046', '1293147034174857218', 5, 4.193199157714844),\n",
       " ('AuRED_059', '1427676759042973697', 1, 8.257699966430664),\n",
       " ('AuRED_059', '1429058202377670669', 2, 7.296599864959717),\n",
       " ('AuRED_059', '1429071449873166346', 3, 7.158199787139893),\n",
       " ('AuRED_059', '1427960605567332353', 4, 6.395899772644043),\n",
       " ('AuRED_059', '1429408005192306694', 5, 5.858799934387207),\n",
       " ('AuRED_033', '1327942301939867648', 1, 9.971500396728516),\n",
       " ('AuRED_033', '1328307341788372994', 2, 9.811699867248535),\n",
       " ('AuRED_033', '1327997706116214786', 3, 8.17609977722168),\n",
       " ('AuRED_033', '1327941038821040129', 4, 7.348899841308594),\n",
       " ('AuRED_033', '1328322422949498882', 5, 7.339300155639648),\n",
       " ('AuRED_001', '1427363982835396609', 1, 11.413800239562988),\n",
       " ('AuRED_001', '1427601535366844436', 2, 11.033100128173828),\n",
       " ('AuRED_001', '1427608828015792144', 3, 10.134499549865723),\n",
       " ('AuRED_001', '1427615537882935297', 4, 9.302900314331055),\n",
       " ('AuRED_001', '1426948149617307656', 5, 7.139699935913086),\n",
       " ('AuRED_039', '937691531187773440', 1, 4.781199932098389),\n",
       " ('AuRED_039', '938807575004565504', 2, 3.688499927520752),\n",
       " ('AuRED_039', '938479853417967618', 3, 3.5859999656677246),\n",
       " ('AuRED_039', '939946780065697792', 4, 3.477400064468384),\n",
       " ('AuRED_039', '938482841729499136', 5, 3.2585999965667725),\n",
       " ('AuRED_076', '1398681800168386563', 1, 6.534900188446045),\n",
       " ('AuRED_076', '1397947843114119171', 2, 5.711299896240234),\n",
       " ('AuRED_076', '1398681786796756993', 3, 4.5792999267578125),\n",
       " ('AuRED_076', '1398681796326400000', 4, 3.7618000507354736),\n",
       " ('AuRED_076', '1398681791201005571', 5, 2.29010009765625),\n",
       " ('AuRED_003', '1225100698918051840', 1, 6.932700157165527),\n",
       " ('AuRED_003', '1224643994568863744', 2, 6.685999870300293),\n",
       " ('AuRED_003', '1225090681460396034', 3, 5.485300064086914),\n",
       " ('AuRED_003', '1224673372946169857', 4, 5.032899856567383),\n",
       " ('AuRED_003', '1226518719469363201', 5, 4.301799774169922)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "for r in tqdm(dev_jsons):\n",
    "    rumor_id = r['id']\n",
    "    query = r['rumor']\n",
    "    timeline = r['timeline']\n",
    "\n",
    "    ranked_docs = searchPyserini(query, timeline)\n",
    "\n",
    "    for rank, (authority_tweet_id, score, doc_text) in enumerate(ranked_docs[:5]):\n",
    "        data += [(rumor_id, authority_tweet_id, rank+1, score)]\n",
    "\n",
    "display(data)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import write_trec_format_output\n",
    "\n",
    "out_path = 'temp-data/lucene-trec.txt'\n",
    "write_trec_format_output(out_path, data, 'LUCENE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def retrieve_relevant_documents(query, timeline):\n",
    "    # Get only doc texts\n",
    "    documents = [t[2] for t in timeline]\n",
    "    tweet_ids = [t[1] for t in timeline]\n",
    "\n",
    "    # Combine query and documents for TF-IDF vectorization\n",
    "    combined_texts = [query] + documents\n",
    "    \n",
    "    # Generate TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(combined_texts)\n",
    "    \n",
    "    # Calculate similarity of the query to each document\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
    "    \n",
    "    # Rank documents based on similarity scores\n",
    "    ranked_doc_indices = similarity_scores.argsort()[0][::-1]\n",
    "\n",
    "    # Sort the documents according to rank\n",
    "    ranked_documents = [documents[i] for i in ranked_doc_indices]\n",
    "    ranked_scores = [similarity_scores[0][i] for i in ranked_doc_indices]\n",
    "    ranked_ids = [tweet_ids[i] for i in ranked_doc_indices]\n",
    "\n",
    "    # Create a list of tuples of shape (doc, score)\n",
    "    ranked_tuples = (list(zip(ranked_ids, ranked_scores, ranked_documents)))\n",
    "    \n",
    "    return ranked_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 118.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "for r in tqdm(dev_jsons):\n",
    "    rumor_id = r['id']\n",
    "    query = r['rumor']\n",
    "    timeline = r['timeline']\n",
    "\n",
    "    ranked_docs = retrieve_relevant_documents(query, timeline)\n",
    "\n",
    "    for rank, (authority_tweet_id, score, doc_text) in enumerate(ranked_docs[:5]):\n",
    "        data += [(rumor_id, authority_tweet_id, rank+1, score)]\n",
    "\n",
    "# display(data)\n",
    "        \n",
    "from utils import write_trec_format_output\n",
    "\n",
    "out_path = 'temp-data/tfidf-trec.txt'\n",
    "write_trec_format_output(out_path, data, 'TFIDF-BASIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_sem = []\n",
    "for i in train_jsons:\n",
    "    docs_sem += [t[2] for t in i['timeline']]\n",
    "\n",
    "docs_sem = list(set(docs_sem))\n",
    "len(docs_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HUB_OFFLINE']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume `documents` is your list of document texts\n",
    "embeddings = model.encode(docs_sem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform K-means clustering\n",
    "num_clusters = 2  # Adjust based on your analysis\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(embeddings)\n",
    "\n",
    "# Use t-SNE for visualization\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(num_clusters):\n",
    "    cluster_indices = kmeans.labels_ == i\n",
    "    plt.scatter(reduced_embeddings[cluster_indices, 0], reduced_embeddings[cluster_indices, 1], label=f'Cluster {i}')\n",
    "plt.legend()\n",
    "plt.title('t-SNE visualization of document clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "from pyterrier.measures import *\n",
    "from ir_measures import R, MAP\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "def evaluate_run(pred_path,golden_path):\n",
    "    golden = pt.io.read_qrels(golden_path)\n",
    "    pred=pt.io._read_results_trec(pred_path)\n",
    "    eval=pt.Evaluate(pred, golden , metrics = [R@5,MAP],perquery=False)\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample \t {'R@5': 0.6357894736842106, 'AP': 0.5612280701754385}\n",
      "lucence  {'R@5': 0.6950877192982456, 'AP': 0.6355555555555555}\n",
      "tfidf \t {'R@5': 0.6687719298245615, 'AP': 0.593157894736842}\n"
     ]
    }
   ],
   "source": [
    "task5_dir = '../clef2024-checkthat-lab/task5'\n",
    "sample_submission_file = task5_dir + '/submission_samples/KGAT_zeroShot_evidence_English_dev.txt'\n",
    "lucene_submission_file = 'temp-data/lucene-trec.txt'\n",
    "tfidf_submission_file = 'temp-data/tfidf-trec.txt'\n",
    "golden_labels_file = task5_dir + '/data/dev_qrels.txt'\n",
    "out_file = 'temp-data/out.csv'\n",
    "\n",
    "print('sample', '\\t', evaluate_run(sample_submission_file,golden_labels_file))\n",
    "print('lucence', '', evaluate_run(lucene_submission_file,golden_labels_file))\n",
    "print('tfidf', '\\t', evaluate_run(tfidf_submission_file,golden_labels_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

import os
from clef.pipeline.pipeline import main, step_retrieval, step_verification
from clef.utils.data_loading import AuredDataset

#
# define parameters
#

root_path = '../../' # path to github repository root level (where setup.py is located)

data_path = os.path.join(root_path, 'clef2024-checkthat-lab', 'task5', 'data')

# for preprocess in [True, False]:
#     for add_author_name in [True, False]:
#         for add_author_bio in [True, False]:
#             for retriever_type in ['TFIDF', 'SBERT', 'OPENAI']: #,'LUCENE']
#                 config = {
#                     'preprocess': preprocess,
#                     'add_author_name': add_author_name,
#                     'add_author_bio': add_author_bio,
#                     'out_dir': './data-out/setup1-exp',
#                     'retriever_k': 5,
#                     'retriever_label': retriever_type
#                 }
#                 run_pipe(filepath, golden_labels_file, config)


retriever_r5_score = {
    'TERRIER': (0, {}),
    'OPENAI': (0, {})
}

for preprocess in [True, False]:
    for retriever_type in retriever_r5_score.keys(): 
        config = {
            'split': 'dev',
            'preprocess': preprocess,
            'add_author_name': False,
            'add_author_bio': False,
            'out_dir': './data-out/experiments/one',
            'retriever_k': 5,
            'retriever_label': retriever_type,
        }

        if config["split"] == "train":
            json_data_filepath = os.path.join(data_path, 'English_train.json') # relative to root
            golden_labels_file = os.path.join(root_path, 'clef', 'data', 'train_qrels.txt') # relative to root, was generated by luis

        elif config["split"] == "dev":
            json_data_filepath = os.path.join(data_path, 'English_dev.json') # relative to root
            golden_labels_file = os.path.join(data_path, 'dev_qrels.txt') # relative to root

        ds = AuredDataset(json_data_filepath, **config)
        # ds.rumors = ds.rumors[0:2] # subset here
        r5, meanap = step_retrieval(ds, config, golden_labels_file)
        if r5 and config:
        retriever_r5_score[retriever_type] = (r5, config)

# select best retriever
max_key = max(retriever_r5_score, key=lambda retriever: retriever_r5_score[retriever][0]) # get key with highest lambda, which is r5

expanded_config = {
    # keep data preprocessing info from best previous step
    **retriever_r5_score[max_key][1],
    # add new config info on decisionmaking params, etc.
    **{
        'normalize_scores': True,
        'scale': False, 
        'ignore_nei': True,
    }
}

print(f"Using best retriever by R@5 : {retriever_r5_score[max_key]}")
print(f"\tChosen from among: {retriever_r5_score.keys()}")
step_verification(ds, expanded_config, json_data_filepath)
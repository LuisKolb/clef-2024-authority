{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # the device to load the model onto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "\n",
    "# TODO: quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_compute_dtype=torch.int,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "#              model_id, \n",
    "#              device_map=\"auto\",\n",
    "#              quantization_config=quantization_config,)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6942eb8e5934037988f96a3b09eabbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111d5960a2f54b53b8a2f7bb5290399a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33bebcf704b40389d3462f830382fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df0866c23a54fef83c79ef7eec9c63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43273aed581840379dd9ccbec07c2d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a0cf289c2c43148c24b4ed2b3d7d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939462dffd9043eb8919d88a1bb9d43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   733, 16289, 28793,  1824,   349,   574, 16020,  2076,  2487,\n",
       "         28804,   733, 28748, 16289, 28793,  6824, 28725,   315, 28742, 28719,\n",
       "          3448, 10473,   298,   264,  1179, 11322, 19961,   302,  6138, 23598,\n",
       "         18342, 28723,   661, 13633,   776,   272,  1103,  3558,   302,   686,\n",
       "         16944, 15637,   423,   298,  5681,   315, 28742, 28719, 13198,   582,\n",
       "           297,   272,  6132, 28808,     2,   733, 16289, 28793,  2378,   368,\n",
       "           506,   993,  7136,   864, 21116, 28804,   733, 28748, 16289, 28793]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = encodeds.to(device)\n",
    "model_inputs\n",
    "# model_4bit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model_4bit.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 96 training json objects and 32 dev objects\n"
     ]
    }
   ],
   "source": [
    "from utils import load_rumors_from_jsonl\n",
    "import os\n",
    "\n",
    "out_dir = './temp-data'\n",
    "\n",
    "clef_path = '../clef2024-checkthat-lab/task5'\n",
    "data_path = os.path.join(clef_path, 'data')\n",
    "\n",
    "filepath_train = os.path.join(data_path, 'English_train.json')\n",
    "filepath_dev = os.path.join(data_path, 'English_dev.json')\n",
    "\n",
    "train_jsons = load_rumors_from_jsonl(filepath_train)\n",
    "dev_jsons = load_rumors_from_jsonl(filepath_dev)\n",
    "\n",
    "print(f'loaded {len(train_jsons)} training json objects and {len(dev_jsons)} dev objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clef.utils import clean_tweet\n",
    "\n",
    "data_cleaned_train = []\n",
    "\n",
    "for entry in train_jsons:\n",
    "    \n",
    "    tl_clean = []\n",
    "    for account_url, tl_tweet_id, tl_tweet in entry['timeline']:\n",
    "        tl_tweet_cleaned = clean_tweet(tl_tweet)\n",
    "        if tl_tweet_cleaned:\n",
    "            tl_clean += [[account_url, tl_tweet_id, tl_tweet_cleaned]]\n",
    "\n",
    "    ev_clean = []\n",
    "    for account_url, ev_tweet_id, ev_tweet in entry['evidence']:\n",
    "        ev_tweet_cleaned = clean_tweet(ev_tweet)\n",
    "        if ev_tweet_cleaned:\n",
    "            ev_clean += [[account_url, ev_tweet_id, ev_tweet_cleaned]]\n",
    "\n",
    "    data_cleaned_train += [{\n",
    "        'id': entry['id'],\n",
    "        'rumor': clean_tweet(entry['rumor']),\n",
    "        'label': entry['label'],\n",
    "        'timeline': tl_clean,\n",
    "        'evidence': ev_clean,\n",
    "    }]\n",
    "\n",
    "# data_cleaned_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clef.utils import clean_tweet\n",
    "\n",
    "data_cleaned_dev = []\n",
    "\n",
    "for entry in dev_jsons:\n",
    "    \n",
    "    tl_clean = []\n",
    "    for account_url, tl_tweet_id, tl_tweet in entry['timeline']:\n",
    "        tl_tweet_cleaned = clean_tweet(tl_tweet)\n",
    "        if tl_tweet_cleaned:\n",
    "            tl_clean += [[account_url, tl_tweet_id, tl_tweet_cleaned]]\n",
    "\n",
    "    ev_clean = []\n",
    "    for account_url, ev_tweet_id, ev_tweet in entry['evidence']:\n",
    "        ev_tweet_cleaned = clean_tweet(ev_tweet)\n",
    "        if ev_tweet_cleaned:\n",
    "            ev_clean += [[account_url, ev_tweet_id, ev_tweet_cleaned]]\n",
    "\n",
    "    data_cleaned_dev += [{\n",
    "        'id': entry['id'],\n",
    "        'rumor': clean_tweet(entry['rumor']),\n",
    "        'label': entry['label'],\n",
    "        'timeline': tl_clean,\n",
    "        'evidence': ev_clean,\n",
    "    }]\n",
    "\n",
    "# data_cleaned_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def retrieve_relevant_documents_sbert(rumor_id, query, timeline): #, debug=False, evidence=[]):\n",
    "    corpus = [t[2] for t in timeline]\n",
    "    corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "    top_k = min(5, len(corpus))\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    # if debug:\n",
    "    #     print(\"\\n\\n======================\\n\\n\")\n",
    "    #     print(\"Query:\", query)\n",
    "    #     evidence_ids = [e[1] for e in evidence]\n",
    "\n",
    "    found = []\n",
    "    docs = []\n",
    "\n",
    "    for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "            id = timeline[idx][1]\n",
    "\n",
    "            # if debug:\n",
    "            #     is_evidence = id in evidence_ids\n",
    "            #     star = \"(*)\" if is_evidence else \"\\t\"\n",
    "            #     print(star, '\\t', \"(Rank: {:.0f})\".format(i+1), \"(Score: {:.4f})\".format(score), corpus[idx])\n",
    "            #     if is_evidence: found += [id]\n",
    "\n",
    "            docs += [[rumor_id, id, i+1, score.item()]]\n",
    "\n",
    "    # if debug:    \n",
    "    #     for _, ev_id, ev_text in evidence:\n",
    "    #         if ev_id not in found:\n",
    "    #                 print('(!) ', ev_text)\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for item in data_cleaned_dev[:]:\n",
    "    query = item['rumor']\n",
    "    timeline = item['timeline']\n",
    "    data += retrieve_relevant_documents_sbert(item['id'], query, timeline)\n",
    "\n",
    "from utils import write_trec_format_output\n",
    "\n",
    "out_path = 'temp-data/sbert-trec-dev.txt'\n",
    "write_trec_format_output(out_path, data, 'SBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample \t {'R@5': 0.6357894736842106, 'AP': 0.5612280701754385}\n",
      "lucence  {'R@5': 0.0, 'AP': 0.0}\n",
      "tfidf \t {'R@5': 0.7235087719298245, 'AP': 0.6301754385964913}\n",
      "terrier  {'R@5': 0.05263157894736842, 'AP': 0.05263157894736842}\n",
      "sbert \t {'R@5': 0.7080701754385965, 'AP': 0.6363508771929824}\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pyterrier.io as ptio\n",
    "import pyterrier.pipelines as ptpipelines\n",
    "from ir_measures import R, MAP    \n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "def evaluate_run(pred_path,golden_path):\n",
    "    golden = ptio.read_qrels(golden_path)\n",
    "    pred= ptio._read_results_trec(pred_path)\n",
    "    eval= ptpipelines.Evaluate(pred, golden , metrics = [R@5,MAP],perquery=False)\n",
    "    return eval\n",
    "\n",
    "task5_dir = '../clef2024-checkthat-lab/task5'\n",
    "sample_submission_file = task5_dir + '/submission_samples/KGAT_zeroShot_evidence_English_dev.txt'\n",
    "lucene_submission_file = 'temp-data/lucene-trec.txt'\n",
    "tfidf_submission_file = 'temp-data/tfidf-trec.txt'\n",
    "terrier_submission_file = 'temp-data/terrier-trec.txt'\n",
    "sbert_submission_file = 'temp-data/sbert-trec-dev.txt'\n",
    "\n",
    "golden_labels_file = task5_dir + '/data/dev_qrels.txt'\n",
    "out_file = 'temp-data/out.csv'\n",
    "\n",
    "print('sample', '\\t', evaluate_run(sample_submission_file,golden_labels_file))\n",
    "print('lucence', '', evaluate_run(lucene_submission_file,golden_labels_file))\n",
    "print('tfidf', '\\t', evaluate_run(tfidf_submission_file,golden_labels_file))\n",
    "print('terrier', '', evaluate_run(terrier_submission_file,golden_labels_file))\n",
    "print('sbert', '\\t', evaluate_run(sbert_submission_file,golden_labels_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
